{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import daal4py as d4p\n",
    "import os,sys,time\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\pearl\\anaconda3\\envs\\daal\\lib\\site-packages\\ipykernel_launcher.py:13: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time 0.2818316000000003\n",
      "accuracy_score 0.95775\n",
      "precision_score 0.9571618356058407\n",
      "recall_score 0.9574422555601799\n",
      "f1_score 0.9572627831746068\n",
      "confusion_matrix\n",
      " [[695   0   0   0  57]\n",
      " [  0 823  14   8   0]\n",
      " [  0   8 810   2   0]\n",
      " [  0   7   1 760   0]\n",
      " [ 72   0   0   0 743]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\pearl\\anaconda3\\envs\\daal\\lib\\site-packages\\ipykernel_launcher.py:43: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    }
   ],
   "source": [
    "#KNN\n",
    "\n",
    "# let's try to use pandas' fast csv reader\n",
    "try:\n",
    "    import pandas\n",
    "    read_csv = lambda f, c, t=np.float64: pandas.read_csv(f, usecols=c, delimiter=',', header=None, dtype=t)\n",
    "except:\n",
    "    # fall back to numpy loadtxt\n",
    "    read_csv = lambda f, c, t=np.float64: np.loadtxt(f, usecols=c, delimiter=',', ndmin=2)\n",
    "\n",
    "\n",
    "def main(readcsv=read_csv, method='defaultDense'):\n",
    "    start = time.clock() # 开始计时\n",
    "    \n",
    "    # Input data set parameters\n",
    "    train_file = os.path.join('data', 'k_nearest_neighbors_train.csv')\n",
    "    predict_file  = os.path.join('data', 'k_nearest_neighbors_test.csv')\n",
    "\n",
    "    # Read data. Let's use 5 features per observation\n",
    "    nFeatures = 5\n",
    "    nClasses = 5\n",
    "    train_data   = readcsv(train_file, range(nFeatures))\n",
    "    train_labels = readcsv(train_file, range(nFeatures, nFeatures+1))\n",
    "\n",
    "    # Create an algorithm object and call compute\n",
    "    train_algo = d4p.kdtree_knn_classification_training(nClasses=nClasses)\n",
    "    # 'weights' is optional argument, let's use equal weights\n",
    "    # in this case results must be the same as without weights\n",
    "    weights = np.ones((train_data.shape[0], 1))\n",
    "    train_result = train_algo.compute(train_data, train_labels, weights)\n",
    "\n",
    "    # Now let's do some prediction\n",
    "    predict_data = readcsv(predict_file, range(nFeatures))\n",
    "    predict_labels = readcsv(predict_file, range(nFeatures, nFeatures+1))\n",
    "                        \n",
    "    # Create an algorithm object and call compute\n",
    "    predict_algo = d4p.kdtree_knn_classification_prediction()\n",
    "    predict_result = predict_algo.compute(predict_data, train_result.model)\n",
    "    \n",
    "    # We expect less than 170 mispredicted values\n",
    "    assert np.count_nonzero(predict_labels != predict_result.prediction) < 170\n",
    "    \n",
    "    end=time.clock() #结束计时\n",
    "    print(\"time\", end-start)\n",
    "\n",
    "    return (train_result, predict_result, predict_labels)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    (train_result, predict_result, predict_labels) = main()\n",
    "#     print(predict_result.prediction.shape)\n",
    "#     print(predict_labels.shape)\n",
    "    print(\"accuracy_score\", accuracy_score(predict_labels, predict_result.prediction))\n",
    "    print(\"precision_score\", precision_score(predict_labels, predict_result.prediction,average=\"macro\"))\n",
    "    print(\"recall_score\", recall_score(predict_labels, predict_result.prediction, average=\"macro\"))\n",
    "    print(\"f1_score\", f1_score(predict_labels, predict_result.prediction, average=\"macro\"))\n",
    "    print(\"confusion_matrix\\n\", confusion_matrix(predict_labels, predict_result.prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\pearl\\anaconda3\\envs\\daal\\lib\\site-packages\\ipykernel_launcher.py:13: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time 0.6110118\n",
      "accuracy_score 0.971\n",
      "precision_score 0.971037103710371\n",
      "recall_score 0.9709918839675359\n",
      "f1_score 0.9709989559624146\n",
      "confusion_matrix\n",
      " [[977  25]\n",
      " [ 33 965]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\pearl\\anaconda3\\envs\\daal\\lib\\site-packages\\ipykernel_launcher.py:38: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "\n",
    "# let's try to use pandas' fast csv reader\n",
    "try:\n",
    "    import pandas\n",
    "    read_csv = lambda f, c, t=np.float64: pandas.read_csv(f, usecols=c, delimiter=',', header=None, dtype=t)\n",
    "except:\n",
    "    # fall back to numpy loadtxt\n",
    "    read_csv = lambda f, c, t=np.float64: np.loadtxt(f, usecols=c, delimiter=',', ndmin=2)\n",
    "\n",
    "\n",
    "def main(readcsv=read_csv, method='defaultDense'):\n",
    "    start = time.clock()\n",
    "    # input data file\n",
    "    infile = \"./data/svm_two_class_train_dense.csv\"\n",
    "    testfile = \"./data/svm_two_class_test_dense.csv\"\n",
    "\n",
    "    # Configure a SVM object to use rbf kernel (and adjusting cachesize)\n",
    "    kern = d4p.kernel_function_linear(method=method)  # need an object that lives when creating train_algo\n",
    "    train_algo = d4p.svm_training(doShrinking=True, kernel=kern, cacheSize=600000000)\n",
    "    \n",
    "    # Read data. Let's use features per observation\n",
    "    data   = readcsv(infile, range(20))\n",
    "    labels = readcsv(infile, range(20,21))\n",
    "    train_result = train_algo.compute(data, labels)\n",
    "\n",
    "    # Now let's do some prediction\n",
    "    predict_algo = d4p.svm_prediction(kernel=kern)\n",
    "    # read test data (with same #features)\n",
    "    pdata = readcsv(testfile, range(20))\n",
    "    plabels = readcsv(testfile, range(20,21))\n",
    "    # now predict using the model from the training above\n",
    "    predict_result = predict_algo.compute(pdata, train_result.model)\n",
    "\n",
    "    # Prediction result provides prediction\n",
    "    assert(predict_result.prediction.shape == (pdata.shape[0], 1))\n",
    "    \n",
    "    end=time.clock() #结束计时\n",
    "    print(\"time\", end-start)\n",
    "    \n",
    "    return (predict_result, plabels)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    (predict_result, predict_labels) = main()\n",
    "    #predict_labels = np.squeeze(predict_labels)\n",
    "#     print(predict_labels.shape)\n",
    "#     print(predict_result.prediction.shape)\n",
    "#     print(predict_result.prediction)\n",
    "#     官方的包写错了，没有进行二值化，这里进行改正\n",
    "    for i in range(len(predict_result.prediction)):\n",
    "        if predict_result.prediction[i][0]>=0:\n",
    "            predict_result.prediction[i][0]=1\n",
    "        else:\n",
    "            predict_result.prediction[i][0]=-1\n",
    "#     print(predict_result.prediction)\n",
    "    print(\"accuracy_score\", accuracy_score(predict_labels, predict_result.prediction))\n",
    "    print(\"precision_score\", precision_score(predict_labels, predict_result.prediction, average=\"macro\"))\n",
    "    print(\"recall_score\", recall_score(predict_labels, predict_result.prediction, average=\"macro\"))\n",
    "    print(\"f1_score\", f1_score(predict_labels, predict_result.prediction, average=\"macro\"))\n",
    "    print(\"confusion_matrix\\n\", confusion_matrix(predict_labels, predict_result.prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\pearl\\anaconda3\\envs\\daal\\lib\\site-packages\\ipykernel_launcher.py:12: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time 0.2384398000000001\n",
      "accuracy_score 1.0\n",
      "precision_score 1.0\n",
      "recall_score 1.0\n",
      "f1_score 1.0\n",
      "confusion_matrix\n",
      " [[ 83   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0  90   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0 104   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0  91   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0  95   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0  93   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0  97   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0 106   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0  92   0   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0 105   0   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 107   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  98   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0 115   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 103   0   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 109   0   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 109   0   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 106   0\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  97\n",
      "    0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "  101   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0  99]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\pearl\\anaconda3\\envs\\daal\\lib\\site-packages\\ipykernel_launcher.py:37: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    }
   ],
   "source": [
    "#朴素贝叶斯\n",
    "# let's try to use pandas' fast csv reader\n",
    "try:\n",
    "    import pandas\n",
    "    read_csv = lambda f, c, t=np.float64: pandas.read_csv(f, usecols=c, delimiter=',', header=None, dtype=t)\n",
    "except:\n",
    "    # fall back to numpy loadtxt\n",
    "    read_csv = lambda f, c, t=np.float64: np.loadtxt(f, usecols=c, delimiter=',', ndmin=2)\n",
    "\n",
    "\n",
    "def main(readcsv=read_csv, method='defaultDense'):\n",
    "    start = time.clock()\n",
    "    \n",
    "    # input data file\n",
    "    infile = \"./data/naivebayes_train_dense.csv\"\n",
    "    testfile = \"./data/naivebayes_test_dense.csv\"\n",
    "\n",
    "    # Configure a training object (20 classes)\n",
    "    talgo = d4p.multinomial_naive_bayes_training(20, method=method)\n",
    "    \n",
    "    # Read data. Let's use 20 features per observation\n",
    "    data   = readcsv(infile, range(20))\n",
    "    labels = readcsv(infile, range(20,21))\n",
    "    tresult = talgo.compute(data, labels)\n",
    "\n",
    "    # Now let's do some prediction\n",
    "    palgo = d4p.multinomial_naive_bayes_prediction(20, method=method)\n",
    "    # read test data (with same #features)\n",
    "    pdata = readcsv(testfile, range(20))\n",
    "    plabels = readcsv(testfile, range(20,21))\n",
    "    # now predict using the model from the training above\n",
    "    presult = palgo.compute(pdata, tresult.model)\n",
    "\n",
    "    # Prediction result provides prediction\n",
    "    assert(presult.prediction.shape == (pdata.shape[0], 1))\n",
    "    \n",
    "    end=time.clock() #结束计时\n",
    "    print(\"time\", end-start)\n",
    "    \n",
    "    return (presult, plabels)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    (predict_result, predict_labels) = main()\n",
    "    print(\"accuracy_score\", accuracy_score(predict_labels, predict_result.prediction))\n",
    "    print(\"precision_score\", precision_score(predict_labels, predict_result.prediction, average=\"macro\"))\n",
    "    print(\"recall_score\", recall_score(predict_labels, predict_result.prediction, average=\"macro\"))\n",
    "    print(\"f1_score\", f1_score(predict_labels, predict_result.prediction, average=\"macro\"))\n",
    "    print(\"confusion_matrix\\n\", confusion_matrix(predict_labels, predict_result.prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\pearl\\anaconda3\\envs\\daal\\lib\\site-packages\\ipykernel_launcher.py:13: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time 0.24148510000000023\n",
      "accuracy_score 1.0\n",
      "precision_score 1.0\n",
      "recall_score 1.0\n",
      "f1_score 1.0\n",
      "confusion_matrix\n",
      " [[1599    0]\n",
      " [   0  401]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\pearl\\anaconda3\\envs\\daal\\lib\\site-packages\\ipykernel_launcher.py:40: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    }
   ],
   "source": [
    "# adaboost\n",
    "\n",
    "# let's try to use pandas' fast csv reader\n",
    "try:\n",
    "    import pandas\n",
    "    read_csv = lambda f, c, t=np.float64: pandas.read_csv(f, usecols=c, delimiter=',', header=None, dtype=t)\n",
    "except:\n",
    "    # fall back to numpy loadtxt\n",
    "    read_csv = lambda f, c, t=np.float64: np.loadtxt(f, usecols=c, delimiter=',', ndmin=2)\n",
    "\n",
    "\n",
    "def main(readcsv=read_csv, method='defaultDense'):\n",
    "    start  = time.clock()\n",
    "    \n",
    "    infile = \"./data/adaboost_train.csv\"\n",
    "    testfile = \"./data/adaboost_test.csv\"\n",
    "    nClasses = 2\n",
    "\n",
    "    # Configure a adaboost training object\n",
    "    train_algo = d4p.adaboost_training(nClasses=nClasses)\n",
    "    \n",
    "    # Read data. Let's have 20 independent, and 1 dependent variable (for each observation)\n",
    "    indep_data = readcsv(infile, range(20))\n",
    "    dep_data   = readcsv(infile, range(20,21))\n",
    "    # Now train/compute, the result provides the model for prediction\n",
    "    train_result = train_algo.compute(indep_data, dep_data)\n",
    "\n",
    "    # Now let's do some prediction\n",
    "    predict_algo = d4p.adaboost_prediction(nClasses=nClasses)\n",
    "    # read test data (with same #features)\n",
    "    pdata = readcsv(testfile, range(20))\n",
    "    # now predict using the model from the training above\n",
    "    predict_result = predict_algo.compute(pdata, train_result.model)\n",
    "\n",
    "    # The prediction result provides prediction\n",
    "    assert predict_result.prediction.shape == (pdata.shape[0], dep_data.shape[1])\n",
    "    predict_labels = np.loadtxt(testfile, usecols=range(20,21), delimiter=',', ndmin=2)\n",
    "    assert np.allclose(predict_result.prediction, predict_labels)\n",
    "    \n",
    "    end=time.clock() #结束计时\n",
    "    print(\"time\", end-start)\n",
    "    \n",
    "    return (train_result, predict_result, predict_labels)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    (train_result, predict_result, predict_labels) = main()\n",
    "    print(\"accuracy_score\", accuracy_score(predict_labels, predict_result.prediction))\n",
    "    print(\"precision_score\", precision_score(predict_labels, predict_result.prediction,average=\"macro\"))\n",
    "    print(\"recall_score\", recall_score(predict_labels, predict_result.prediction, average=\"macro\"))\n",
    "    print(\"f1_score\", f1_score(predict_labels, predict_result.prediction, average=\"macro\"))\n",
    "    print(\"confusion_matrix\\n\", confusion_matrix(predict_labels, predict_result.prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\pearl\\anaconda3\\envs\\daal\\lib\\site-packages\\ipykernel_launcher.py:16: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time 1.9564907999999992\n",
      "accuracy_score 0.972\n",
      "precision_score 0.9724331546028709\n",
      "recall_score 0.9724483374081128\n",
      "f1_score 0.9723101652373585\n",
      "confusion_matrix\n",
      " [[161   2   0   0   0]\n",
      " [  2 155   3   0   0]\n",
      " [  0   8 310   2   0]\n",
      " [  0   0   5 193   0]\n",
      " [  0   0   0   6 153]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\pearl\\anaconda3\\envs\\daal\\lib\\site-packages\\ipykernel_launcher.py:53: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    }
   ],
   "source": [
    "# 随机森林RandomFroest\n",
    "\n",
    "# let's try to use pandas' fast csv reader\n",
    "try:\n",
    "    import pandas\n",
    "    read_csv = lambda f, c, t=np.float64: pandas.read_csv(f, usecols=c, delimiter=',', header=None, dtype=t)\n",
    "except:\n",
    "    # fall back to numpy loadtxt\n",
    "    read_csv = lambda f, c, t=np.float64: np.loadtxt(f, usecols=c, delimiter=',', ndmin=2, dtype=t)\n",
    "\n",
    "# Get Intel(R) Data Analytics Acceleration Library (Intel(R) DAAL) version\n",
    "from daal4py import __daal_link_version__ as dv\n",
    "daal_version = tuple(map(int, (dv[0:4], dv[4:8])))\n",
    "\n",
    "def main(readcsv=read_csv, method='defaultDense'):\n",
    "    start = time.clock()\n",
    "    # input data file\n",
    "    infile = \"./data/df_classification_train.csv\"\n",
    "    testfile = \"./data/df_classification_test.csv\"\n",
    "\n",
    "    # Configure a training object (5 classes)\n",
    "    train_algo = d4p.decision_forest_classification_training(5,\n",
    "                                                             nTrees=10,\n",
    "                                                             minObservationsInLeafNode=8,\n",
    "                                                             featuresPerNode=3,\n",
    "                                                             engine = d4p.engines_mt19937(seed=777),\n",
    "                                                             varImportance='MDI',\n",
    "                                                             bootstrap=True,\n",
    "                                                             resultsToCompute='computeOutOfBagError')\n",
    "\n",
    "    # Read data. Let's use 3 features per observation\n",
    "    data   = readcsv(infile, range(3), t=np.float32)\n",
    "    labels = readcsv(infile, range(3,4), t=np.float32)\n",
    "    train_result = train_algo.compute(data, labels)\n",
    "    # Traiing result provides (depending on parameters) model, outOfBagError, outOfBagErrorPerObservation and/or variableImportance\n",
    "\n",
    "    # Now let's do some prediction\n",
    "    predict_algo = d4p.decision_forest_classification_prediction(nClasses=5)\n",
    "#     if daal_version < (2020,1):\n",
    "#         predict_algo = d4p.decision_forest_classification_prediction(nClasses=5)\n",
    "#     else:\n",
    "#         predict_algo = d4p.decision_forest_classification_prediction(nClasses=5,\n",
    "#             resultsToEvaluate=\"computeClassLabels|computeClassProbabilities\", votingMethod=\"unweighted\")\n",
    "    # read test data (with same #features)\n",
    "    pdata = readcsv(testfile, range(3), t=np.float32)\n",
    "    plabels = readcsv(testfile, range(3,4), t=np.float32)\n",
    "    # now predict using the model from the training above\n",
    "    predict_result = predict_algo.compute(pdata, train_result.model)\n",
    "\n",
    "    # Prediction result provides prediction\n",
    "    assert(predict_result.prediction.shape == (pdata.shape[0], 1))\n",
    "    \n",
    "    end=time.clock() #结束计时\n",
    "    print(\"time\", end-start)\n",
    "    return (train_result, predict_result, plabels)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    (train_result, predict_result, predict_labels) = main()\n",
    "    print(\"accuracy_score\", accuracy_score(predict_labels, predict_result.prediction))\n",
    "    print(\"precision_score\", precision_score(predict_labels, predict_result.prediction, average=\"macro\"))\n",
    "    print(\"recall_score\", recall_score(predict_labels, predict_result.prediction, average=\"macro\"))\n",
    "    print(\"f1_score\", f1_score(predict_labels, predict_result.prediction, average=\"macro\"))\n",
    "    print(\"confusion_matrix\\n\", confusion_matrix(predict_labels, predict_result.prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time 0.004831300000001093\n",
      "Weights:\n",
      " [[0.50004707 0.49995293]]\n",
      "Means:\n",
      " [[10.16638183  0.04546081 -7.21141   ]\n",
      " [ 0.19393028  0.01859487  0.37642873]]\n",
      "Covariance:\n",
      " [[ 7.56786995  1.30583815 -0.06336321]\n",
      " [ 1.30583815  0.97932635  0.63631872]\n",
      " [-0.06336321  0.63631872  2.27659338]]\n",
      "Covariance:\n",
      " [[ 0.85968907 -0.22851204  0.08127243]\n",
      " [-0.22851204  2.2197825  -0.10165961]\n",
      " [ 0.08127243 -0.10165961  2.57295252]]\n",
      "All looks good!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\pearl\\anaconda3\\envs\\daal\\lib\\site-packages\\ipykernel_launcher.py:13: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  del sys.path[0]\n",
      "f:\\pearl\\anaconda3\\envs\\daal\\lib\\site-packages\\ipykernel_launcher.py:30: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    }
   ],
   "source": [
    "# EM算法\n",
    "\n",
    "# let's try to use pandas' fast csv reader\n",
    "try:\n",
    "    import pandas\n",
    "    read_csv = lambda f, c=None, t=np.float64: pandas.read_csv(f, usecols=c, delimiter=',', header=None, dtype=t)\n",
    "except:\n",
    "    # fall back to numpy loadtxt\n",
    "    read_csv = lambda f, c=None, t=np.float64: np.loadtxt(f, usecols=c, delimiter=',', ndmin=2)\n",
    "\n",
    "\n",
    "def main(readcsv=read_csv, method='defaultDense'):\n",
    "    start = time.clock()\n",
    "    nComponents = 2\n",
    "    infile = \"./data/em_gmm.csv\"\n",
    "    # We load the data\n",
    "    data = readcsv(infile)\n",
    "\n",
    "    # configure a em_gmm init object\n",
    "    algo1 = d4p.em_gmm_init(nComponents)\n",
    "    # and compute initial model\n",
    "    result1 = algo1.compute(data)\n",
    "\n",
    "    # configure a em_gmm object\n",
    "    algo2 = d4p.em_gmm(nComponents)\n",
    "\n",
    "    # and compute em_gmm using initial weights and means\n",
    "    result2 = algo2.compute(data, result1.weights, result1.means, result1.covariances)\n",
    "    \n",
    "    end=time.clock() #结束计时\n",
    "    print(\"time\", end-start)\n",
    "    \n",
    "    # implicit als prediction result objects provide covariances, goalFunction, means, nIterations and weights\n",
    "    return result2\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    res = main()\n",
    "    # daal库的api不支持预测\n",
    "    print(\"Weights:\\n\", res.weights)\n",
    "    print(\"Means:\\n\", res.means)\n",
    "    for c in res.covariances:\n",
    "        print(\"Covariance:\\n\", c)\n",
    "    print('All looks good!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\pearl\\anaconda3\\envs\\daal\\lib\\site-packages\\ipykernel_launcher.py:13: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time 0.12507719999999978\n",
      "MAE 2.7084110872930176\n",
      "MSE 17.652745413976746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\pearl\\anaconda3\\envs\\daal\\lib\\site-packages\\ipykernel_launcher.py:42: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    }
   ],
   "source": [
    "# 随机森林回归\n",
    "\n",
    "# let's try to use pandas' fast csv reader\n",
    "try:\n",
    "    import pandas\n",
    "    read_csv = lambda f, c, t=np.float64: pandas.read_csv(f, usecols=c, delimiter=',', header=None, dtype=np.float32)\n",
    "except:\n",
    "    # fall back to numpy loadtxt\n",
    "    read_csv = lambda f, c, t=np.float64: np.loadtxt(f, usecols=c, delimiter=',', ndmin=2, dtype=np.float32)\n",
    "\n",
    "\n",
    "def main(readcsv=read_csv, method='defaultDense'):\n",
    "    start = time.clock()\n",
    "    infile = \"./data/df_regression_train.csv\"\n",
    "    testfile = \"./data/df_regression_test.csv\"\n",
    "\n",
    "    # Configure a Linear regression training object\n",
    "    train_algo = d4p.decision_forest_regression_training(nTrees=100,\n",
    "                                                         varImportance='MDA_Raw',\n",
    "                                                         bootstrap=True,\n",
    "                                                         engine = d4p.engines_mt2203(seed=777),\n",
    "                                                         resultsToCompute='computeOutOfBagError|computeOutOfBagErrorPerObservation')\n",
    "    \n",
    "    # Read data. Let's have 13 independent, and 1 dependent variables (for each observation)\n",
    "    indep_data = readcsv(infile, range(13), t=np.float32)\n",
    "    dep_data   = readcsv(infile, range(13,14), t=np.float32)\n",
    "    # Now train/compute, the result provides the model for prediction\n",
    "    train_result = train_algo.compute(indep_data, dep_data)\n",
    "    # Traiing result provides (depending on parameters) model, outOfBagError, outOfBagErrorPerObservation and/or variableImportance\n",
    "\n",
    "    # Now let's do some prediction\n",
    "    predict_algo = d4p.decision_forest_regression_prediction()\n",
    "    # read test data (with same #features)\n",
    "    pdata = readcsv(testfile, range(13), t=np.float32)\n",
    "    ptdata = readcsv(testfile, range(13,14), t=np.float32)\n",
    "    # now predict using the model from the training above\n",
    "    predict_result = predict_algo.compute(pdata, train_result.model)\n",
    "\n",
    "    # The prediction result provides prediction\n",
    "    assert predict_result.prediction.shape == (pdata.shape[0], dep_data.shape[1])\n",
    "    \n",
    "    end=time.clock() #结束计时\n",
    "    print(\"time\", end-start)\n",
    "    \n",
    "    return (train_result, predict_result, ptdata)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    from daal4py import __daal_link_version__ as dv\n",
    "    daal_version = tuple(map(int, (dv[0:4], dv[4:8])))\n",
    "    if daal_version < (2019, 1):\n",
    "        print(\"Need Intel(R) DAAL 2019.1 or later\")\n",
    "    else:\n",
    "        (train_result, predict_result, ptdata) = main()\n",
    "        print(\"MAE\", mean_absolute_error(ptdata, predict_result.prediction))\n",
    "        print(\"MSE\", mean_squared_error(ptdata, predict_result.prediction))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
